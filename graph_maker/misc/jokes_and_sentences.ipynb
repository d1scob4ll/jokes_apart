{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import statistics\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Читаем файлы с анекдотами из директории: /home/lanayawiz/main/maga/jokes/aneks/\n",
      "Обрабатываем файл: /home/lanayawiz/main/maga/jokes/aneks/anek_cleaned.txt\n",
      "  Добавлено анекдотов: 124155\n",
      "Обрабатываем файл: /home/lanayawiz/main/maga/jokes/aneks/dataset.txt\n",
      "  Добавлено анекдотов: 2\n",
      "Обрабатываем файл: /home/lanayawiz/main/maga/jokes/aneks/extract_anekdots.txt\n",
      "  Добавлено анекдотов: 87720\n",
      "Обрабатываем файл: /home/lanayawiz/main/maga/jokes/aneks/jokes.txt\n",
      "  Добавлено анекдотов: 2\n",
      "Обрабатываем файл: /home/lanayawiz/main/maga/jokes/aneks/jokes_2.txt\n",
      "  Добавлено анекдотов: 132570\n",
      "\n",
      "Всего прочитано анекдотов: 344449\n",
      "Сохраняем все анекдоты в файл: /home/lanayawiz/main/maga/jokes/aneks/aneks.txt\n",
      "Файл aneks.txt успешно создан.\n",
      "\n",
      "Анализ структуры анекдотов:\n"
     ]
    }
   ],
   "source": [
    "def read_text_units_single_line(filename):\n",
    "    text_units = []\n",
    "    current_unit_lines = []\n",
    "\n",
    "    try:\n",
    "        with open(filename, 'r', encoding='utf-8') as file:\n",
    "            for line in file:\n",
    "                stripped_line = line.strip()\n",
    "\n",
    "                if stripped_line:\n",
    "                    current_unit_lines.append(stripped_line)\n",
    "                else:\n",
    "                    if current_unit_lines:\n",
    "                        unit_text = ' '.join(current_unit_lines)\n",
    "                        text_units.append(unit_text)\n",
    "                        current_unit_lines = []\n",
    "\n",
    "            if current_unit_lines:\n",
    "                unit_text = ' '.join(current_unit_lines)\n",
    "                text_units.append(unit_text)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Ошибка: Файл '{filename}' не найден.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Произошла ошибка при чтении файла '{filename}': {e}\")\n",
    "\n",
    "    return text_units\n",
    "\n",
    "anek_files = [\n",
    "    'anek_cleaned.txt',\n",
    "    'dataset.txt',\n",
    "    'extract_anekdots.txt',\n",
    "    'jokes.txt',\n",
    "    'jokes_2.txt'\n",
    "]\n",
    "\n",
    "anek_dir = os.path.expanduser('~/main/maga/jokes/aneks/') \n",
    "all_aneks = []\n",
    "\n",
    "print(f\"Читаем файлы с анекдотами из директории: {anek_dir}\")\n",
    "\n",
    "for filename in anek_files:\n",
    "    file_path = os.path.join(anek_dir, filename)\n",
    "    print(f\"Обрабатываем файл: {file_path}\")\n",
    "    aneks_from_file = read_text_units_single_line(file_path)\n",
    "    all_aneks.extend(aneks_from_file)\n",
    "    print(f\"  Добавлено анекдотов: {len(aneks_from_file)}\")\n",
    "\n",
    "print(f\"\\nВсего прочитано анекдотов: {len(all_aneks)}\")\n",
    "\n",
    "output_anek_file = os.path.join(anek_dir, 'aneks.txt') \n",
    "print(f\"Сохраняем все анекдоты в файл: {output_anek_file}\")\n",
    "try:\n",
    "    with open(output_anek_file, 'w', encoding='utf-8') as f:\n",
    "        for anek in all_aneks:\n",
    "            f.write(anek + '\\n')\n",
    "    print(\"Файл aneks.txt успешно создан.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при записи файла aneks.txt: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Анализ количества слов ---\n",
      "Общее количество анекдотов: 344449\n",
      "Среднее количество слов: 36.91\n",
      "Стандартное отклонение (сигма) слов: 6184.01\n",
      "Минимальное количество слов: 10\n",
      "Максимальное количество слов: 90\n",
      "\n",
      "Распределение количества слов по диапазонам:\n",
      "  0-9: 61422\n",
      "  10-19: 157434\n",
      "  20-29: 72127\n",
      "  30-39: 25616\n",
      "  40-49: 10479\n",
      "  50-59: 5395\n",
      "  60-69: 3402\n",
      "  70-79: 2375\n",
      "  80-89: 1599\n",
      "  90-99: 1097\n",
      "  100-109: 918\n",
      "  110-119: 680\n",
      "  120-129: 496\n",
      "  130-139: 389\n",
      "  140-149: 256\n",
      "  150-159: 219\n",
      "  160-169: 147\n",
      "  170-179: 84\n",
      "  180-189: 49\n",
      "  190-199: 49\n",
      "  200-209: 35\n",
      "  210-219: 27\n",
      "  220-229: 21\n",
      "  230-239: 22\n",
      "  240-249: 15\n",
      "  250-259: 15\n",
      "  260-269: 5\n",
      "  270-279: 6\n",
      "  280-289: 7\n",
      "  290-299: 7\n",
      "  300-309: 4\n",
      "  310-319: 3\n",
      "  320-329: 3\n",
      "  330-339: 2\n",
      "  340-349: 7\n",
      "  350-359: 4\n",
      "  360-369: 5\n",
      "  370-379: 3\n",
      "  380-389: 1\n",
      "  390-399: 1\n",
      "  420-429: 1\n",
      "  440-449: 3\n",
      "  450-459: 3\n",
      "  460-469: 1\n",
      "  480-489: 1\n",
      "  530-539: 1\n",
      "  550-559: 2\n",
      "  560-569: 3\n",
      "  570-579: 1\n",
      "  620-629: 1\n",
      "  680-689: 1\n",
      "  810-819: 1\n",
      "  160430-160439: 1\n",
      "  524450-524459: 1\n",
      "  1894150-1894159: 1\n",
      "  3046950-3046959: 1\n",
      "\n",
      "--- Анализ количества символов ---\n",
      "Общее количество анекдотов: 344449\n",
      "Среднее количество символов: 234.48\n",
      "Стандартное отклонение (сигма) символов: 39766.53\n",
      "Минимальное количество символов: 50\n",
      "Максимальное количество символов: 500\n",
      "\n",
      "Распределение количества символов по диапазонам:\n",
      "  0-49: 36088\n",
      "  50-99: 133128\n",
      "  100-149: 92526\n",
      "  150-199: 36883\n",
      "  200-249: 17888\n",
      "  250-299: 8836\n",
      "  300-349: 5024\n",
      "  350-399: 3374\n",
      "  400-449: 2486\n",
      "  450-499: 1821\n",
      "  500-549: 1378\n",
      "  550-599: 1021\n",
      "  600-649: 821\n",
      "  650-699: 675\n",
      "  700-749: 515\n",
      "  750-799: 462\n",
      "  800-849: 325\n",
      "  850-899: 256\n",
      "  900-949: 219\n",
      "  950-999: 183\n",
      "  1000-1049: 108\n",
      "  1050-1099: 70\n",
      "  1100-1149: 47\n",
      "  1150-1199: 55\n",
      "  1200-1249: 33\n",
      "  1250-1299: 28\n",
      "  1300-1349: 20\n",
      "  1350-1399: 29\n",
      "  1400-1449: 17\n",
      "  1450-1499: 20\n",
      "  1500-1549: 10\n",
      "  1550-1599: 12\n",
      "  1600-1649: 11\n",
      "  1650-1699: 9\n",
      "  1700-1749: 6\n",
      "  1750-1799: 3\n",
      "  1800-1849: 2\n",
      "  1850-1899: 7\n",
      "  1900-1949: 3\n",
      "  1950-1999: 2\n",
      "  2000-2049: 4\n",
      "  2050-2099: 1\n",
      "  2100-2149: 2\n",
      "  2150-2199: 1\n",
      "  2200-2249: 5\n",
      "  2250-2299: 2\n",
      "  2300-2349: 1\n",
      "  2350-2399: 1\n",
      "  2450-2499: 1\n",
      "  2500-2549: 4\n",
      "  2550-2599: 2\n",
      "  2600-2649: 2\n",
      "  2650-2699: 2\n",
      "  2700-2749: 1\n",
      "  2850-2899: 1\n",
      "  2900-2949: 2\n",
      "  3000-3049: 1\n",
      "  3050-3099: 1\n",
      "  3150-3199: 1\n",
      "  3550-3599: 2\n",
      "  3650-3699: 1\n",
      "  3750-3799: 2\n",
      "  3900-3949: 1\n",
      "  3950-3999: 1\n",
      "  4350-4399: 1\n",
      "  5000-5049: 1\n",
      "  1037000-1037049: 1\n",
      "  3374750-3374799: 1\n",
      "  12169550-12169599: 1\n",
      "  19599650-19599699: 1\n"
     ]
    }
   ],
   "source": [
    "if all_aneks:\n",
    "    word_counts = [len(anek.split()) for anek in all_aneks]\n",
    "    char_counts = [len(anek) for anek in all_aneks]\n",
    "\n",
    "    total_aneks = len(all_aneks)\n",
    "\n",
    "    print(\"\\n--- Анализ количества слов ---\")\n",
    "    print(f\"Общее количество анекдотов: {total_aneks}\")\n",
    "\n",
    "    if total_aneks > 1: \n",
    "        avg_words = statistics.mean(word_counts)\n",
    "        stdev_words = statistics.stdev(word_counts)\n",
    "        min_words = 10\n",
    "        max_words = 90\n",
    "\n",
    "        print(f\"Среднее количество слов: {avg_words:.2f}\")\n",
    "        print(f\"Стандартное отклонение (сигма) слов: {stdev_words:.2f}\")\n",
    "        print(f\"Минимальное количество слов: {min_words}\")\n",
    "        print(f\"Максимальное количество слов: {max_words}\")\n",
    "\n",
    "        print(\"\\nРаспределение количества слов по диапазонам:\")\n",
    "        word_bins = Counter()\n",
    "        bin_size_words = 10 \n",
    "        max_bin_limit_words = max_words + bin_size_words - (max_words % bin_size_words)\n",
    "\n",
    "        for count in word_counts:\n",
    "             bin_start = (count // bin_size_words) * bin_size_words\n",
    "             bin_end = bin_start + bin_size_words - 1\n",
    "             bin_key = f\"{bin_start}-{bin_end}\"\n",
    "             word_bins[bin_key] += 1\n",
    "\n",
    "        sorted_word_bins = sorted(word_bins.items(), key=lambda item: int(item[0].split('-')[0]))\n",
    "\n",
    "        for bin_range, count in sorted_word_bins:\n",
    "             print(f\"  {bin_range}: {count}\")\n",
    "\n",
    "    elif total_aneks == 1:\n",
    "         print(f\"Количество слов: {word_counts[0]}\")\n",
    "         print(\"Стандартное отклонение не может быть рассчитано для одного элемента.\")\n",
    "    else:\n",
    "        print(\"Нет данных для анализа количества слов.\")\n",
    "\n",
    "\n",
    "    print(\"\\n--- Анализ количества символов ---\")\n",
    "    print(f\"Общее количество анекдотов: {total_aneks}\")\n",
    "\n",
    "    if total_aneks > 1:\n",
    "        avg_chars = statistics.mean(char_counts)\n",
    "        stdev_chars = statistics.stdev(char_counts)\n",
    "        min_chars = 50\n",
    "        max_chars = 500\n",
    "\n",
    "        print(f\"Среднее количество символов: {avg_chars:.2f}\")\n",
    "        print(f\"Стандартное отклонение (сигма) символов: {stdev_chars:.2f}\")\n",
    "        print(f\"Минимальное количество символов: {min_chars}\")\n",
    "        print(f\"Максимальное количество символов: {max_chars}\")\n",
    "\n",
    "        print(\"\\nРаспределение количества символов по диапазонам:\")\n",
    "        char_bins = Counter()\n",
    "        bin_size_chars = 50 \n",
    "        max_bin_limit_chars = max_chars + bin_size_chars - (max_chars % bin_size_chars)ов\n",
    "\n",
    "        for count in char_counts:\n",
    "            \n",
    "            bin_start = (count // bin_size_chars) * bin_size_chars\n",
    "            bin_end = bin_start + bin_size_chars - 1\n",
    "            bin_key = f\"{bin_start}-{bin_end}\"\n",
    "            char_bins[bin_key] += 1\n",
    "\n",
    "\n",
    "        sorted_char_bins = sorted(char_bins.items(), key=lambda item: int(item[0].split('-')[0]))\n",
    "\n",
    "        for bin_range, count in sorted_char_bins:\n",
    "             print(f\"  {bin_range}: {count}\")\n",
    "\n",
    "    elif total_aneks == 1:\n",
    "         print(f\"Количество символов: {char_counts[0]}\")\n",
    "         print(\"Стандартное отклонение не может быть рассчитано для одного элемента.\")\n",
    "    else:\n",
    "        print(\"Нет данных для анализа количества символов.\")\n",
    "\n",
    "else:\n",
    "    print(\"Список анекдотов пуст. Невозможно провести анализ структуры.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка файла: aneks.txt\n",
      "Удаляем строки длиннее 1000000 символов.\n",
      "Обработка завершена.\n",
      "Всего строк прочитано: 344448\n",
      "Строк удалено (длиннее 1000000 символов): 4\n",
      "Строк оставлено: 344444\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "input_filename = 'aneks.txt'\n",
    "output_filename_tmp = input_filename + '.tmp'\n",
    "\n",
    "char_limit = 1000000\n",
    "\n",
    "lines_removed_count = 0\n",
    "total_lines_count = 0\n",
    "\n",
    "print(f\"Обработка файла: {input_filename}\")\n",
    "print(f\"Удаляем строки длиннее {char_limit} символов.\")\n",
    "\n",
    "try:\n",
    "    with open(input_filename, 'r', encoding='utf-8') as infile, \\\n",
    "         open(output_filename_tmp, 'w', encoding='utf-8') as outfile:\n",
    "\n",
    "        for line in infile:\n",
    "            total_lines_count += 1\n",
    "            if len(line) <= char_limit:\n",
    "                outfile.write(line)\n",
    "            else:\n",
    "                lines_removed_count += 1\n",
    "\n",
    "    os.replace(output_filename_tmp, input_filename)\n",
    "\n",
    "    print(\"Обработка завершена.\")\n",
    "    print(f\"Всего строк прочитано: {total_lines_count}\")\n",
    "    print(f\"Строк удалено (длиннее {char_limit} символов): {lines_removed_count}\")\n",
    "    print(f\"Строк оставлено: {total_lines_count - lines_removed_count}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Ошибка: Файл '{input_filename}' не найден. Убедитесь, что он находится в той же папке, что и скрипт, или укажите полный путь.\")\n",
    "except Exception as e:\n",
    "    print(f\"Произошла ошибка в процессе обработки: {e}\")\n",
    "    if os.path.exists(output_filename_tmp):\n",
    "        os.remove(output_filename_tmp)\n",
    "        print(f\"Временный файл '{output_filename_tmp}' удален из-за ошибки.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_distribution_data = {\n",
    "    10: 61422,\n",
    "    20: 157434, \n",
    "    30: 72127,\n",
    "    40: 25616,\n",
    "    50: 10479,\n",
    "    60: 5395, \n",
    "    70: 3402, \n",
    "    80: 2375, \n",
    "    90: 1599, \n",
    "    100: 1097,\n",
    "    110: 918, \n",
    "    120: 680, \n",
    "    130: 496, \n",
    "    140: 389, \n",
    "    150: 256, \n",
    "    160: 219, \n",
    "    170: 147, \n",
    "    180: 84, \n",
    "    190: 49, \n",
    "    200: 49, \n",
    "    210: 35, \n",
    "    220: 27, \n",
    "    float('inf'): 0 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Целевое общее количество предложений: 344295\n",
      "Собираем РУССКИЕ предложения из папки: /home/lanayawiz/main/concept-tree/prose\n",
      "Собрано всего ПОДХОДЯЩИХ (русских) предложений из исходных текстов: 7117688\n",
      "Количество собранных русских предложений по бинам:\n",
      "  0-9 слов : 3690697\n",
      "  10-19 слов : 2381179\n",
      "  20-29 слов : 725591\n",
      "  30-39 слов : 208594\n",
      "  40-49 слов : 66657\n",
      "  50-59 слов : 23986\n",
      "  60-69 слов : 10002\n",
      "  70-79 слов : 4684\n",
      "  80-89 слов : 2537\n",
      "  90-99 слов : 1348\n",
      "  100-109 слов : 818\n",
      "  110-119 слов : 491\n",
      "  120-129 слов : 362\n",
      "  130-139 слов : 221\n",
      "  140-149 слов : 120\n",
      "  150-159 слов : 131\n",
      "  160-169 слов : 72\n",
      "  170-179 слов : 69\n",
      "  180-189 слов : 42\n",
      "  190-199 слов : 28\n",
      "  200-209 слов : 25\n",
      "  210-219 слов : 15\n",
      "  220-229 слов : 19\n",
      "\n",
      "Отбираем предложения по целевому распределению aneks.txt...\n",
      "  Из бина 0-9 отобрано 61422/61422 (доступно 3690697)\n",
      "  Из бина 10-19 отобрано 157434/157434 (доступно 2381179)\n",
      "  Из бина 20-29 отобрано 72127/72127 (доступно 725591)\n",
      "  Из бина 30-39 отобрано 25616/25616 (доступно 208594)\n",
      "  Из бина 40-49 отобрано 10479/10479 (доступно 66657)\n",
      "  Из бина 50-59 отобрано 5395/5395 (доступно 23986)\n",
      "  Из бина 60-69 отобрано 3402/3402 (доступно 10002)\n",
      "  Из бина 70-79 отобрано 2375/2375 (доступно 4684)\n",
      "  Из бина 80-89 отобрано 1599/1599 (доступно 2537)\n",
      "  Из бина 90-99 отобрано 1097/1097 (доступно 1348)\n",
      "  Из бина 100-109 отобрано 818/918 (доступно 818)\n",
      "  Из бина 110-119 отобрано 491/680 (доступно 491)\n",
      "  Из бина 120-129 отобрано 362/496 (доступно 362)\n",
      "  Из бина 130-139 отобрано 221/389 (доступно 221)\n",
      "  Из бина 140-149 отобрано 120/256 (доступно 120)\n",
      "  Из бина 150-159 отобрано 131/219 (доступно 131)\n",
      "  Из бина 160-169 отобрано 72/147 (доступно 72)\n",
      "  Из бина 170-179 отобрано 69/84 (доступно 69)\n",
      "  Из бина 180-189 отобрано 42/49 (доступно 42)\n",
      "  Из бина 190-199 отобрано 28/49 (доступно 28)\n",
      "  Из бина 200-209 отобрано 25/35 (доступно 25)\n",
      "  Из бина 210-219 отобрано 15/27 (доступно 15)\n",
      "\n",
      "Всего отобрано предложений для выходного файла: 343340\n",
      "Записываем отобранные предложения в файл: not_aneks_3.txt\n",
      "Файл успешно создан.\n",
      "\n",
      "Анализ распределения в созданном файле (приблизительно):\n",
      "  0-9 слов: 61422\n",
      "  10-19 слов: 157434\n",
      "  20-29 слов: 72127\n",
      "  30-39 слов: 25616\n",
      "  40-49 слов: 10479\n",
      "  50-59 слов: 5395\n",
      "  60-69 слов: 3402\n",
      "  70-79 слов: 2375\n",
      "  80-89 слов: 1599\n",
      "  90-99 слов: 1097\n",
      "  100-109 слов: 818\n",
      "  110-119 слов: 491\n",
      "  120-129 слов: 362\n",
      "  130-139 слов: 221\n",
      "  140-149 слов: 120\n",
      "  150-159 слов: 131\n",
      "  160-169 слов: 72\n",
      "  170-179 слов: 69\n",
      "  180-189 слов: 42\n",
      "  190-199 слов: 28\n",
      "  200-209 слов: 25\n",
      "  210-219 слов: 15\n",
      "  220-229 слов: 0\n",
      "\n",
      "Целевое общее количество из aneks: 344295\n",
      "Фактически отобрано в файл: 343340\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import math\n",
    "\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except nltk.downloader.DownloadError:\n",
    "    nltk.download('punkt')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "\n",
    "\n",
    "\n",
    "bin_ranges = [(0, 10), (10, 20), (20, 30), (30, 40), (40, 50), (50, 60), (60, 70), (70, 80), (80, 90), (90, 100),\n",
    "              (100, 110), (110, 120), (120, 130), (130, 140), (140, 150), (150, 160), (160, 170), (170, 180),\n",
    "              (180, 190), (190, 200), (200, 210), (210, 220), (220, 230)] \n",
    "\n",
    "\n",
    "bin_ranges_with_inf = bin_ranges + [(230, float('inf'))]\n",
    "\n",
    "\n",
    "total_target_count = sum(list(target_distribution_data.values())[:-1]) \n",
    "print(f\"Целевое общее количество предложений: {total_target_count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "source_folder = '/home/lanayawiz/main/concept-tree/prose' \n",
    "sentences_by_bin = defaultdict(list)\n",
    "total_sentences_collected = 0\n",
    "\n",
    "\n",
    "russian_char_pattern = re.compile(r'[а-яА-ЯЁё]')\n",
    "\n",
    "print(f\"Собираем РУССКИЕ предложения из папки: {source_folder}\")\n",
    "\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filepath = os.path.join(source_folder, filename)\n",
    "        \n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "                \n",
    "                text = text.replace('\\n', ' ').replace('\\r', '')\n",
    "                text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "                if not text: \n",
    "                    continue\n",
    "\n",
    "                \n",
    "                sentences = nltk.sent_tokenize(text)\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    \n",
    "                    cleaned_sentence = sentence.strip()\n",
    "\n",
    "                    if not cleaned_sentence: \n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    if not russian_char_pattern.search(cleaned_sentence):\n",
    "                         continue \n",
    "\n",
    "                    \n",
    "                    words = [word for word in cleaned_sentence.split() if word]\n",
    "                    word_count = len(words)\n",
    "\n",
    "                    if word_count == 0: \n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    assigned_bin = None\n",
    "                    for lower, upper in bin_ranges_with_inf:\n",
    "                         if lower <= word_count < upper:\n",
    "                              assigned_bin = (lower, upper)\n",
    "                              break\n",
    "\n",
    "                    \n",
    "                    if assigned_bin in bin_ranges:\n",
    "                         sentences_by_bin[assigned_bin].append(cleaned_sentence)\n",
    "                         total_sentences_collected += 1\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "\n",
    "\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Ошибка кодировки файла: {filepath}. Пропускаем.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке файла {filepath}: {e}. Пропускаем.\")\n",
    "\n",
    "print(f\"Собрано всего ПОДХОДЯЩИХ (русских) предложений из исходных текстов: {total_sentences_collected}\")\n",
    "\n",
    "print(\"Количество собранных русских предложений по бинам:\")\n",
    "collected_counts = {}\n",
    "\n",
    "for lower, upper in bin_ranges:\n",
    "     count = len(sentences_by_bin[(lower, upper)])\n",
    "     collected_counts[(lower, upper)] = count\n",
    "     print(f\"  {lower}-{upper-1} слов : {count}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output_sentences = []\n",
    "\n",
    "print(\"\\nОтбираем предложения по целевому распределению aneks.txt...\")\n",
    "\n",
    "\n",
    "target_counts_for_sampling = {}\n",
    "\n",
    "for key, count in target_distribution_data.items():\n",
    "    if key != float('inf'): \n",
    "        lower_bound = key - 10 if key >= 20 else 0\n",
    "        upper_bound = key\n",
    "        target_counts_for_sampling[(lower_bound, upper_bound)] = count\n",
    "\n",
    "\n",
    "for bin_range, target_count_in_bin in target_counts_for_sampling.items():\n",
    "    available_sentences_in_bin = sentences_by_bin[bin_range]\n",
    "    actual_count_to_sample = min(target_count_in_bin, len(available_sentences_in_bin))\n",
    "\n",
    "    if actual_count_to_sample > 0:\n",
    "        sampled_sentences = random.sample(available_sentences_in_bin, actual_count_to_sample)\n",
    "        output_sentences.extend(sampled_sentences)\n",
    "        print(f\"  Из бина {bin_range[0]}-{bin_range[1]-1} отобрано {actual_count_to_sample}/{target_count_in_bin} (доступно {len(available_sentences_in_bin)})\")\n",
    "    else:\n",
    "        print(f\"  Из бина {bin_range[0]}-{bin_range[1]-1} отобрано 0/{target_count_in_bin} (доступно {len(available_sentences_in_bin)})\")\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(output_sentences)\n",
    "\n",
    "print(f\"\\nВсего отобрано предложений для выходного файла: {len(output_sentences)}\")\n",
    "\n",
    "\n",
    "\n",
    "output_filename = 'not_aneks_3.txt' \n",
    "\n",
    "print(f\"Записываем отобранные предложения в файл: {output_filename}\")\n",
    "\n",
    "try:\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        for sentence in output_sentences:\n",
    "            f.write(sentence + '\\n')\n",
    "    print(\"Файл успешно создан.\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при записи файла {output_filename}: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\nАнализ распределения в созданном файле (приблизительно):\")\n",
    "output_distribution = defaultdict(int)\n",
    "for sentence in output_sentences:\n",
    "    words = [word for word in sentence.split() if word] \n",
    "    word_count = len(words)\n",
    "    assigned_bin = None\n",
    "    for lower, upper in bin_ranges: \n",
    "        if lower <= word_count < upper:\n",
    "            assigned_bin = (lower, upper)\n",
    "            break\n",
    "    if assigned_bin:\n",
    "        output_distribution[assigned_bin] += 1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for lower, upper in bin_ranges:\n",
    "     count = output_distribution.get((lower, upper), 0)\n",
    "     print(f\"  {lower}-{upper-1} слов: {count}\")\n",
    "\n",
    "\n",
    "print(f\"\\nЦелевое общее количество из aneks: {total_target_count}\")\n",
    "print(f\"Фактически отобрано в файл: {len(output_sentences)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
